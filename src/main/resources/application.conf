config-source {
  server-source-name = "spikes-server"
}

# http server configuration
http {
  ip = "localhost"
  port = 8080
  baseUrl = "static"
  defaultPages = ["index.html", "index.htm"]
  timeoutSeconds = 5
  webSocketPath = "web-socket"
}

# apache kafka cluster configuration
kafka {
  bootstrap {
    servers = "localhost:9092, localhost:9093, localhost:9094"
  }
}

# overrides the remote.netty.tcp.port when specified. when multiple actor systems are
# created in remote mode, each system needs a unique port (on this box and on the
# remote box). These are the ports that will be used for this box. On the remote box
# an equivalent set of "available-ports" should be specified.
remoting-ports = [2554..2566, 2568]

# akka configurtion
akka {
//  loglevel = "INFO"
  loglevel = "DEBUG"

  # override the base settings to allow remote neural networks
  actor {
    //      provider = remote
    # -------
    # for testing seriealization
    provider = local
    //      serialize-messages = on
    //      serialize-creators = on
    # -------

  }

  # scheduler tick-duration
  # see https://doc.akka.io/docs/akka/snapshot/general/configuration.html#akka-actor and search for "scheduler"
  scheduler {
    implementation = "com.digitalcipher.spiked.timing.SpikesScheduler"
    tick-duration = 100000ns
    ticks-per-wheel = 1024
  }

  remote {
    //      artery {
    //        enabled = on
    //
    //        # -------
    //        # for testing seriealization
    //        # enabled = off
    //        # -------
    //        canonical.hostname = "192.168.1.153"
    //        canonical.port = 2553
    //      }
    enabled-transports = ["akka.remote.netty.tcp"]
    netty.tcp {
      hostname = "localhost"
      port = 2554
    }
  }

  http.server {
    parsing {
      max-content-length = 110M
    }
  }

  # Properties for akka.kafka.ConsumerSettings can be
  # defined in this section or a configuration section with
  # the same layout.
  kafka.consumer {
    # Tuning property of scheduled polls.
    # Controls the interval from one scheduled poll to the next.
    poll-interval = 50ms

    # Tuning property of the `KafkaConsumer.poll` parameter.
    # Note that non-zero value means that the thread that
    # is executing the stage will be blocked. See also the `wakup-timeout` setting below.
    poll-timeout = 50ms

    # The stage will delay stopping the internal actor to allow processing of
    # messages already in the stream (required for successful committing).
    # Prefer use of `DrainingControl` over a large stop-timeout.
    stop-timeout = 30s

    # Duration to wait for `KafkaConsumer.close` to finish.
    close-timeout = 20s

    # If offset commit requests are not completed within this timeout
    # the returned Future is completed `CommitTimeoutException`.
    # The `Transactional.source` waits this ammount of time for the producer to mark messages as not
    # being in flight anymore as well as waiting for messages to drain, when rebalance is triggered.
    commit-timeout = 15s

    # If commits take longer than this time a warning is logged
    commit-time-warning = 1s

    # Not used anymore (since 1.0-RC1)
    # wakeup-timeout = 3s

    # Not used anymore (since 1.0-RC1)
    # max-wakeups = 10

    # If set to a finite duration, the consumer will re-send the last committed offsets periodically
    # for all assigned partitions. See https://issues.apache.org/jira/browse/KAFKA-4682.
    commit-refresh-interval = infinite

    # Not used anymore (since 1.0-RC1)
    # wakeup-debug = true

    # Fully qualified config path which holds the dispatcher configuration
    # to be used by the KafkaConsumerActor. Some blocking may occur.
    use-dispatcher = "akka.kafka.default-dispatcher"

    # Properties defined by org.apache.kafka.clients.consumer.ConsumerConfig
    # can be defined in this configuration section.
    kafka-clients {
      # Disable auto-commit by default
      enable.auto.commit = false
    }

    # Time to wait for pending requests when a partition is closed
    wait-close-partition = 500ms

    # Limits the query to Kafka for a topic's position
    position-timeout = 5s

    # When using `AssignmentOffsetsForTimes` subscriptions: timeout for the
    # call to Kafka's API
    offset-for-times-timeout = 5s

    # Timeout for akka.kafka.Metadata requests
    # This value is used instead of Kafka's default from `default.api.timeout.ms`
    # which is 1 minute.
    metadata-request-timeout = 5s

    # Interval for checking that transaction was completed before closing the consumer.
    # Used in the transactional flow for exactly-once-semantics processing.
    eos-draining-check-interval = 30ms
  }
}
